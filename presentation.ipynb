{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation 02 - Training Markov Models\n",
    "\n",
    "Brian Bahmanyar - Due: Wednesday, April 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import \"http://fonts.googleapis.com/css?family=Lato|Source+Code+Pro|Montserrat:400,700\";#notebook-container{-webkit-box-shadow:none;box-shadow:none}h1,h2,h3,h4,h5,h6{font-family:'Avenir Next'}h1{font-size:4.5em}h2{font-size:4rem}h3{font-size:3.5rem}h4{font-size:3rem}h5{font-size:2.5rem}h6{font-size:2rem}p{font-family:'Avenir Next';font-size:12pt;line-height:15pt;color:#2F4F4F}.CodeMirror pre{font-family:'Source Code Pro', monospace;font-size:0.95em}div.input_area{border:none;background:whitesmoke}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Please disregard, just some css for styling\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<style>@import \"http://fonts.googleapis.com/css?family=Lato|Source+Code+Pro|Montserrat:400,700\";#notebook-container{-webkit-box-shadow:none;box-shadow:none}h1,h2,h3,h4,h5,h6{font-family:'Avenir Next'}h1{font-size:4.5em}h2{font-size:4rem}h3{font-size:3.5rem}h4{font-size:3rem}h5{font-size:2.5rem}h6{font-size:2rem}p{font-family:'Avenir Next';font-size:12pt;line-height:15pt;color:#2F4F4F}.CodeMirror pre{font-family:'Source Code Pro', monospace;font-size:0.95em}div.input_area{border:none;background:whitesmoke}</style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the markov models will be trained from the coprus in [trump.txt](./trump.txt) which comprises two of Donald Trump's speeches hosted by the Washington Post ([Article 1](https://www.washingtonpost.com/news/post-politics/wp/2015/06/16/full-text-donald-trump-announces-a-presidential-bid/), [Article 2](https://www.washingtonpost.com/news/post-politics/wp/2016/02/20/transcript-donald-trumps-victory-speech-after-the-south-carolina-gop-primary/)). I scraped, cleaned, and tokenized the text from the web pages' HTML, then wrote it to [trump.txt](./trump.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     167    8264 trump.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -lw trump.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus contains 8264 words in total, devided among 167 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## I'm importing functions from the python scripts for use here without copying and pasting\n",
    "##     all the functions. Please refer to the .py files for the implementations.\n",
    "from train_markov_chain import get_transition_matrix\n",
    "from generate_text import simulate_markov_states, get_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Order Markov Model (Bi-Gram Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = get_transition_matrix('trump.txt', markov_model_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1265, 1265)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transition probability matrix is square, as expected, and our state space is 1265 states large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously this transition matrix is going to be very sparse, so showing a slice of it won't be very helpful. Instead I'll display a subset of the state space and confirm that the first 10 row probabilities sum to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['('1',)', '('10',)', '('100',)', '('10000',)', '('12',)', '('1290',)',\n",
       "       '('13',)', '('15',)', '('16',)', '('18',)',\n",
       "       ...\n",
       "       '('yesterday',)', '('yet',)', '('york',)', '('you',)', '('young',)',\n",
       "       '('your',)', '('youre',)', '('yourself',)', '('youve',)', '('zero',)'],\n",
       "      dtype='object', length=1265)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1',)        1\n",
       "('10',)       1\n",
       "('100',)      1\n",
       "('10000',)    1\n",
       "('12',)       1\n",
       "('1290',)     1\n",
       "('13',)       1\n",
       "('15',)       1\n",
       "('16',)       1\n",
       "('18',)       1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have confirmed that our transition matrix is looking good, we can start using it to generate text that resembles the structure of Donald Trump's speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "takes care of 30 the most highly sought after all of political people that sells because my time when do something wrong with oil and thats longterm debt because dont know the world so put together its impossible theyre gonna be the middle east iran from all im totally destabilize the deal its great deals the good thing and my father is going to nevada and lets go to us in in the prison area my life ive watched the world per pupil than us not using a nation in a clue they beat mexico love the airconditioner didnt know henry right on time magazine last time when we cant do a company so thank you look at all talk jobs because buy the smartest negotiators in in mexico thats the cards because again but still hate to do we want to educate their united states zero tax until the military so well you its gonna go to do it it right good we cant do it said is just a good company so tough you cant happen if a gun on television well as an incredible and certify to believe me they dont need somebody that wrote the cards\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(get_text(simulate_markov_states(P, num_states=200))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a first order Markov Model, and generating 200 states, the text generated is pretty scatted and hard to follow (although in the models defense so is the corpus itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of the word frequencies this model is outputing were going to need to simulate much more text. Below I will simulate 100,000 states and display the top 20 most frequent words, and their counts from the 8264 word corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count = Counter() \n",
    "word_count.update(get_text(simulate_markov_states(P, num_states=100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('the', 3727)),\n",
       " (2, ('and', 3552)),\n",
       " (3, ('to', 2867)),\n",
       " (4, ('a', 2250)),\n",
       " (5, ('we', 2207)),\n",
       " (6, ('you', 1709)),\n",
       " (7, ('of', 1669)),\n",
       " (8, ('they', 1569)),\n",
       " (9, ('it', 1556)),\n",
       " (10, ('have', 1497)),\n",
       " (11, ('that', 1470)),\n",
       " (12, ('in', 1257)),\n",
       " (13, ('going', 1104)),\n",
       " (14, ('our', 1006)),\n",
       " (15, ('so', 970)),\n",
       " (16, ('people', 910)),\n",
       " (17, ('its', 842)),\n",
       " (18, ('be', 825)),\n",
       " (19, ('is', 804)),\n",
       " (20, ('are', 788))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(range(1,21), word_count.most_common(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the most generated words are the most common words from the corpus and the most frequently used words in the english language. Such as 'the', 'and', 'to'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Order Markov Model (Tri-Gram Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = get_transition_matrix('trump.txt', markov_model_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5310, 5310)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transition probability matrix is square, as expected, and our state space is 5310 states large. It makes sense that we have a larger state space here as were comparing pairs of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a subset of the state space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['('1', 'billion')', '('10', 'billion')', '('10', 'feet')',\n",
       "       '('10', 'to')', '('100', 'percent')', '('10000', 'we')',\n",
       "       '('12', 'billion')', '('1290', 'avenue')', '('13', 'trillion')',\n",
       "       '('15', 'million')',\n",
       "       ...\n",
       "       '('youre', 'not')', '('youre', 'right')', '('yourself', 'how')',\n",
       "       '('youve', 'seen')', '('zero', 'chance')', '('zero', 'horrible')',\n",
       "       '('zero', 'ill')', '('zero', 'our')', '('zero', 'tax')',\n",
       "       '('zero', 'whoever')'],\n",
       "      dtype='object', length=5310)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets generate 200 states using our Second Order Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall just got 10 feet taller its true and these are the walls because we need trump now our country needs we need somebody we need money were dying were dying we need that thinking we have tremendous people we have nothing and every truck and every part manufactured in this building they make weapons right now and then were going to be amazingly destructive doctors are quitting have a clue hes a bad negotiator hes the one that did bergdahl we get bergdahl we get a lot of them that are obsolete weve got social security thats going to have the opposite thinking we have to get environmental clearance and the finest when mexico sends its people theyre not sending you theyre sending us not the right people so ford will come back theyll all come back and make it great again so ladies and gentlemen am officially running for president would one of my family melania barron kai donnie don vanessa tiffany evanka did a great negotiator learned so much he was a done deal its going to do terrific and the enemy took them we dont need the rhetoric want a job and theyll be proud and theyll\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(get_text(simulate_markov_states(P, num_states=200))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text generated from our Second Order Markov Model here is much more readable and closer to real language than the First Order Model. This is expected because we are breaking fewer links between the words from the original corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of the word frequencies this model is outputing were going to need to simulate much more text. Below I will simulate 100,000 states and display the top 20 most frequent words, and their counts from the 8264 word corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count.clear()\n",
    "word_count.update(get_text(simulate_markov_states(P, num_states=100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('the', 3799)),\n",
       " (2, ('and', 3657)),\n",
       " (3, ('to', 2922)),\n",
       " (4, ('we', 2209)),\n",
       " (5, ('a', 2189)),\n",
       " (6, ('of', 1695)),\n",
       " (7, ('you', 1656)),\n",
       " (8, ('have', 1628)),\n",
       " (9, ('it', 1522)),\n",
       " (10, ('that', 1507)),\n",
       " (11, ('they', 1460)),\n",
       " (12, ('in', 1244)),\n",
       " (13, ('going', 1140)),\n",
       " (14, ('our', 1023)),\n",
       " (15, ('so', 986)),\n",
       " (16, ('people', 973)),\n",
       " (17, ('its', 854)),\n",
       " (18, ('be', 831)),\n",
       " (19, ('is', 782)),\n",
       " (20, ('were', 775))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(range(1,21), word_count.most_common(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, again, the most frequent words generated are 'the', 'and', 'to'. This is a simulation of the non-conditional frequency of the words from the corpus, so with enough state simulations this should not change significantly from model to model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Order Markov Model (4-Gram Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = get_transition_matrix('trump.txt', markov_model_order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7272, 7272)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im making speeches all the time we want trump well you need somebody because politicians are all talk no action nothings gonna get done they will not as an example ive been on the circuit making speeches and hear my fellow republicans and theyre wonderful people like them they all want me to support them they dont see me anymore im making speeches all the time we want trump we want trump we want trump we want trump now our country needs we need that thinking we have the opposite thinking we have losers we have losers we have losers we have losers we have people that are selling this country down the drain so put together this and before say it have to say ted and marco did a really good plan and ill add in the third we had a 9000 we had a 9000 we had a really good job and they wanted to do a lot of beautiful work were going to do a lot of those votes also you dont just add them together so think were going to nevada lead lead with the hispanics im leading in every poll with the hispanics they love me love\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(get_text(simulate_markov_states(P, num_states=200))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the order of the markov model increases we break fewer links between the words from the corpus. This means the generated text will be more natural and readable, but will be very similar to the original corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
